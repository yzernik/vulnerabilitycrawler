   install_special_mapping skips security_file_mmap check.
   
   The install_special_mapping routine (used, for example, to setup the
   vdso) skips the security check before insert_vm_struct, allowing a local
   attacker to bypass the mmap_min_addr security restriction by limiting
   the available pages for special mappings.
   
   bprm_mm_init() also skips the check, and although I don't think this can
   be used to bypass any restrictions, I don't see any reason not to have
   the security check.
   
     $ uname -m
     x86_64
     $ cat /proc/sys/vm/mmap_min_addr
     65536
     $ cat install_special_mapping.s
     section .bss
         resb BSS_SIZE
     section .text
         global _start
         _start:
             mov     eax, __NR_pause
             int     0x80
     $ nasm -D__NR_pause=29 -DBSS_SIZE=0xfffed000 -f elf -o install_special_mapping.o install_special_mapping.s
     $ ld -m elf_i386 -Ttext=0x10000 -Tbss=0x11000 -o install_special_mapping install_special_mapping.o
     $ ./install_special_mapping &
     [1] 14303
     $ cat /proc/14303/maps
     0000f000-00010000 r-xp 00000000 00:00 0                                  [vdso]
     00010000-00011000 r-xp 00001000 00:19 2453665                            /home/taviso/install_special_mapping
     00011000-ffffe000 rwxp 00000000 00:00 0                                  [stack]
   
   It's worth noting that Red Hat are shipping with mmap_min_addr set to
   4096.
   
   Signed-off-by: Tavis Ormandy <taviso@google.com>
   Acked-by: Kees Cook <kees@ubuntu.com>
   Acked-by: Robert Swiecki <swiecki@google.com>
   [ Changed to not drop the error code - akpm ]
   Reviewed-by: James Morris <jmorris@namei.org>
   Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
	INIT_LIST_HEAD(&vma->anon_vma_chain);
	err = insert_vm_struct(mm, vma);
	if (err)
		goto err;
			    unsigned long addr, unsigned long len,
			    unsigned long vm_flags, struct page **pages)
{
	struct vm_area_struct *vma;

	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
	vma->vm_ops = &special_mapping_vmops;
	vma->vm_private_data = pages;

	if (unlikely(insert_vm_struct(mm, vma))) {
		kmem_cache_free(vm_area_cachep, vma);
		return -ENOMEM;
	}

	mm->total_vm += len >> PAGE_SHIFT;

	perf_event_mmap(vma);

	return 0;
}

static DEFINE_MUTEX(mm_all_locks_mutex);
